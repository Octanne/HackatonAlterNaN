WARNING: If MPI_Abort is called during execution, result files could not be copied.
Running: mpiexec -n 2 --tag-output /opt/aster/install/mpi/bin/run_aster -n 2 --wrkdir /tmp/run_aster_r9rxyg_u --status-file /home/aster/.tmp_run_aster/run_aster_1hqa1zu5/__status__ --no-mpi /home/aster/.tmp_run_aster/run_aster_1hqa1zu5/Cube_perf.0
[1,0]<stdout>:
[1,0]<stdout>:# ------------------------------------------------------------------------------
[1,0]<stdout>:Execution of code_aster
[1,0]<stdout>:
[1,0]<stdout>:# ------------------------------------------------------------------------------
[1,0]<stdout>:Prepare environment in /tmp/run_aster_r9rxyg_u/proc.0
[1,0]<stdout>:
[1,0]<stdout>:# ------------------------------------------------------------------------------
[1,0]<stdout>:Command file #1 / 1
[1,1]<stdout>:
[1,1]<stdout>:# ------------------------------------------------------------------------------
[1,1]<stdout>:Execution of code_aster
[1,1]<stdout>:
[1,1]<stdout>:# ------------------------------------------------------------------------------
[1,1]<stdout>:Prepare environment in /tmp/run_aster_r9rxyg_u/proc.1
[1,1]<stdout>:
[1,1]<stdout>:# ------------------------------------------------------------------------------
[1,1]<stdout>:Command file #1 / 1
[1,0]<stdout>:
[1,0]<stdout>:Content of the file to execute:
[1,0]<stdout>:# coding=utf-8
[1,0]<stdout>:#!/usr/bin/python
[1,0]<stdout>:
[1,0]<stdout>:import os
[1,0]<stdout>:from statistics import mean
[1,0]<stdout>:from datetime import datetime
[1,0]<stdout>:from resource import RUSAGE_SELF, getrusage
[1,0]<stdout>:
[1,0]<stdout>:from code_aster.Commands import *
[1,0]<stdout>:from code_aster import CA
[1,0]<stdout>:from code_aster.Utilities import petscInitialize
[1,0]<stdout>:
[1,0]<stdout>:CA.init()
[1,0]<stdout>:
[1,0]<stdout>:params = {}
[1,0]<stdout>:params["refinements"] = int(os.environ.get("REFINE", 1))
[1,0]<stdout>:params["parallel"] = os.environ.get("USE_LEGACY", "HPC")
[1,0]<stdout>:params["solver"] = os.environ.get("SOLVER", "PETSC")
[1,0]<stdout>:
[1,0]<stdout>:# General parameters
[1,0]<stdout>:comm = CA.MPI.ASTER_COMM_WORLD
[1,0]<stdout>:rank = comm.Get_rank()
[1,0]<stdout>:size = comm.Get_size()
[1,0]<stdout>:
[1,0]<stdout>:nbHexa = 8 ** params["refinements"]
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:def memory_peak(mess=None):
[1,0]<stdout>:    """Return memory peak in MB"""
[1,0]<stdout>:    return int(getrusage(RUSAGE_SELF).ru_maxrss / 1024)
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:class ChronoCtxMgGen:
[1,0]<stdout>:    stats = {}
[1,0]<stdout>:
[1,0]<stdout>:    def __init__(self, what):
[1,0]<stdout>:        self._what = what
[1,0]<stdout>:
[1,0]<stdout>:    def __enter__(self):
[1,0]<stdout>:        self.start = datetime.now()
[1,0]<stdout>:
[1,0]<stdout>:    def __exit__(self, exctype, exc, tb):
[1,0]<stdout>:        self.stop = datetime.now()
[1,0]<stdout>:        delta = self.stop - self.start
[1,0]<stdout>:        mem = memory_peak(self._what)
[1,0]<stdout>:        self.stats[self._what] = [delta.total_seconds(), mem]
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:class ChronoCtxMg(ChronoCtxMgGen):
[1,0]<stdout>:    pass
[1,0]<stdout>:    # def __init__(self, what):
[1,0]<stdout>:    #     ChronoCtxMgGen.__init__(self, what)
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:def write_stats(nume_ddl):
[1,0]<stdout>:    if rank == 0:
[1,0]<stdout>:        print("TITLE: TEST PERF CUBE")
[1,0]<stdout>:        print()
[1,0]<stdout>:        print("NB PROC")
[1,0]<stdout>:        print(size)
[1,0]<stdout>:        print()
[1,0]<stdout>:        print(
[1,0]<stdout>:            "COMMAND, TIME MIN (s), TIME MAX (s), TIME MEAN (s), MEM MIN (Mo), MEM MAX (Mo), MEM MEAN (Mo)"
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    for key, values in stats.items():
[1,0]<stdout>:        time = comm.gather(values[0], root=0)
[1,0]<stdout>:        mem = comm.gather(values[1], root=0)
[1,0]<stdout>:        if rank == 0:
[1,0]<stdout>:            print(
[1,0]<stdout>:                key
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(min(time))
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(max(time))
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(mean(time))
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(min(mem))
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(max(mem))
[1,0]<stdout>:                + ", "
[1,0]<stdout>:                + str(m[1,0]<stdout>:ean(mem))
[1,0]<stdout>:            )
[1,0]<stdout>:
[1,0]<stdout>:    mesh = nume_ddl.getMesh()
[1,0]<stdout>:    nodes = len(mesh.getInnerNodes())
[1,0]<stdout>:    nodes = comm.allreduce(nodes, CA.MPI.SUM)
[1,0]<stdout>:
[1,0]<stdout>:    if rank == 0:
[1,0]<stdout>:        print()
[1,0]<stdout>:        print("NB CELLS, NB NODES, NB DOFS")
[1,0]<stdout>:        print(str(nbHexa) + ", " + str(nodes) + ", " + str(nume_ddl.getNumberOfDofs()))
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:def print_markdown_table(data, refine, nbcells, nbnodes, nbdofs):
[1,0]<stdout>:    """Print a table of the mean time as a Markdown table."""
[1,0]<stdout>:
[1,0]<stdout>:    def show(*args, **kwargs):
[1,0]<stdout>:        if rank == 0:
[1,0]<stdout>:            print(*args, **kwargs)
[1,0]<stdout>:
[1,0]<stdout>:    fmti = "| {0:<16s} | {1:11,d} |"
[1,0]<stdout>:    fmtt = "| {0:<16s} | {1:11.2f} |"
[1,0]<stdout>:    separ = "| :--------------- | ----------: |"
[1,0]<stdout>:    show(fmti.format("Refinement", refine))
[1,0]<stdout>:    show(separ)
[1,0]<stdout>:    show(fmti.format("Number of cells", nbcells).replace(",", " "))
[1,0]<stdout>:    show(fmti.format("Number of nodes", nbnodes).replace(",", " "))
[1,0]<stdout>:    show(fmti.format("Number of DOFs", nbdofs).replace(",", " "))
[1,0]<stdout>:    show(fmti.format("Number of procs", size).replace(",", " "))
[1,0]<stdout>:    show(fmti.format("Nb of DOFs/proc", nbdofs // size).replace(",", " "))
[1,0]<stdout>:    for key, values in data.items():
[1,0]<stdout>:        times = comm.gather(values[0], root=0)
[1,0]<stdout>:        # mem = comm.gather(values[1], root=0)
[1,0]<stdout>:        if rank == 0:
[1,0]<stdout>:            show(fmtt.format(key, mean(times)))
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:# petscInitialize('-ksp_monitor_true_residual -stats' )
[1,0]<stdout>:petscInitialize("-ksp_monitor_true_residual -log_view")
[1,0]<stdout>:
[1,0]<stdout>:with ChronoCtxMg("Total"):
[1,0]<stdout>:    with ChronoCtxMg("Build mesh"):
[1,0]<stdout>:        if params["parallel"] == "HPC":
[1,0]<stdout>:            mesh = CA.ParallelMesh.buildCube(refine=params["refinements"])
[1,0]<stdout>:        else:
[1,0]<stdout>:            mesh = CA.Mesh.buildCube(refine=params["refinements"])
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Model"):
[1,0]<stdout>:        model = AFFE_MODELE(
[1,0]<stdout>:            MAILLAGE=mesh,
[1,0]<stdout>:            AFFE=_F(
[1,0]<stdout>:                TOUT="OUI",
[1,0]<stdout>:                PHENOMENE="MECANIQUE",
[1,0]<stdout>:                MODELISATION="3D",
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Material"):
[1,0]<stdout>:        steel = DEFI_MATERIAU(
[1,0]<stdout>:            ELAS=_F(
[1,0]<stdout>:                E=200000.0,
[1,0]<stdout>:                NU=0.3,
[1,0]<stdout>:            ),
[1,0]<stdout>:            ECRO_LINE=_F(
[1,0]<stdout>:    [1,0]<stdout>:            D_SIGM_EPSI=2000.0,
[1,0]<stdout>:                SY=200.0,
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:        mater = AFFE_MATERIAU(
[1,0]<stdout>:            MAILLAGE=mesh,
[1,0]<stdout>:            AFFE=_F(
[1,0]<stdout>:                TOUT="OUI",
[1,0]<stdout>:                MATER=steel,
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Boundary conditions"):
[1,0]<stdout>:        block = AFFE_CHAR_CINE(
[1,0]<stdout>:            MODELE=model,
[1,0]<stdout>:            MECA_IMPO=(
[1,0]<stdout>:                _F(
[1,0]<stdout>:                    GROUP_MA="LEFT",
[1,0]<stdout>:                    DX=0,
[1,0]<stdout>:                    DY=0.0,
[1,0]<stdout>:                    DZ=0.0,
[1,0]<stdout>:                ),
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:        imposed_displ = AFFE_CHAR_CINE(
[1,0]<stdout>:            MODELE=model,
[1,0]<stdout>:            MECA_IMPO=(
[1,0]<stdout>:                _F(
[1,0]<stdout>:                    GROUP_MA="RIGHT",
[1,0]<stdout>:                    DY=0.001,
[1,0]<stdout>:                    DZ=0.001,
[1,0]<stdout>:                ),
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Create matrix"):
[1,0]<stdout>:        stiff_elem = CALC_MATR_ELEM(
[1,0]<stdout>:            MODELE=model,
[1,0]<stdout>:            OPTION="RIGI_MECA",
[1,0]<stdout>:            CHAM_MATER=mater,
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Numbering"):
[1,0]<stdout>:        dofNum = NUME_DDL(
[1,0]<stdout>:            MATR_RIGI=stiff_elem,
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Assembly"):
[1,0]<stdout>:        stiffness = ASSE_MATRICE(
[1,0]<stdout>:            MATR_ELEM=stiff_elem,
[1,0]<stdout>:            NUME_DDL=dofNum,
[1,0]<stdout>:            CHAR_CINE=(block, imposed_displ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Build RHS"):
[1,0]<stdout>:        rhs = CREA_CHAMP(
[1,0]<stdout>:            TYPE_CHAM="NOEU_DEPL_R",
[1,0]<stdout>:            OPERATION="AFFE",
[1,0]<stdout>:            MAILLAGE=mesh,
[1,0]<stdout>:            AFFE=_F(
[1,0]<stdout>:                TOUT="OUI",
[1,0]<stdout>:                NOM_CMP=(
[1,0]<stdout>:                    "DX",
[1,0]<stdout>:                    "DY",
[1,0]<stdout>:                    "DZ",
[1,0]<stdout>:                ),
[1,0]<stdout>:                VALE=(
[1,0]<stdout>:                    0.0,
[1,0]<stdout>:                    0.0,
[1,0]<stdout>:                    0.0,
[1,0]<stdout>:                ),
[1,0]<stdout>:            ),
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:        load_vector = CALC_CHAR_CINE(NUME_DDL=dofNum, CHAR_CINE=(block, imposed_displ))
[1,0]<stdout>:
[1,0]<stdout>:    if params["solver"] == "PETSC":
[1,0]<stdout>:        solver = CA.PetscSolver(RENUM="SANS", PRE_COND="GAMG")
[1,0]<stdout>:    elif params["solver"] == "MUMPS":
[1,0]<stdout>:        solver = CA.MumpsSolver(
[1,0]<stdout>:            MATR_DISTRIBUEE="OUI",
[1,0]<stdout>:            RENUM="PARMETIS",
[1,0]<stdout>:            ACCELERATION="FR+",
[1,0]<stdout>:            POSTTRAITEMENTS="MINI",
[1,0]<stdout>:        )
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Factorize"):
[1,0]<stdout>:        solver.factorize(stiffness)
[1,0]<stdout>:
[1,0]<stdout>:    with ChronoCtxMg("Solve"):
[1,0]<stdout>:        resu = solver.solve(rhs, load_vector)
[1,0]<stdout>:
[1,0]<stdout>:# write_stats(dofNum)
[1,0]<stdout>:nbNodes = len(mesh.getInnerNodes())
[1,0]<stdout>:if params["parallel"] == "HPC":
[1,0]<stdout>:    nbNodes = comm.allreduce(nbNodes, CA.MPI.SUM)
[1,0]<stdout>:nbDOFs = dofNum.getNumberOfDOFs()
[1,0]<stdout>:print_markdown_table(ChronoCtxMg.stats, params["refinements"], nbHexa, nbNodes, nbDOFs)
[1,0]<stdout>:
[1,0]<stdout>:CA.close()
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:# ------------------------------------------------------------------------------
[1,0]<stdout>:Command line #1:
[1,0]<stdout>:    ulimit -c unlimited ; ulimit -t 108000 ; ( /opt/venv/bin/python3 -m mpi4py /home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/Cube_perf.py --last --tpmax 86400 ; echo $? > _exit_code_ ) 2>&1 | tee -a fort.6
[1,1]<stdout>:
[1,1]<stdout>:Content of the file to execute:
[1,1]<stdout>:# coding=utf-8
[1,1]<stdout>:#!/usr/bin/python
[1,1]<stdout>:
[1,1]<stdout>:import os
[1,1]<stdout>:from statistics import mean
[1,1]<stdout>:from datetime import datetime
[1,1]<stdout>:from resource import RUSAGE_SELF, getrusage
[1,1]<stdout>:
[1,1]<stdout>:from code_aster.Commands import *
[1,1]<stdout>:from code_aster import CA
[1,1]<stdout>:from code_aster.Utilities import petscInitialize
[1,1]<stdout>:
[1,1]<stdout>:CA.init()
[1,1]<stdout>:
[1,1]<stdout>:params = {}
[1,1]<stdout>:params["refinements"] = int(os.environ.get("REFINE", 1))
[1,1]<stdout>:params["parallel"] = os.environ.get("USE_LEGACY", "HPC")
[1,1]<stdout>:params["solver"] = os.environ.get("SOLVER", "PETSC")
[1,1]<stdout>:
[1,1]<stdout>:# General parameters
[1,1]<stdout>:comm = CA.MPI.ASTER_COMM_WORLD
[1,1]<stdout>:rank = comm.Get_rank()
[1,1]<stdout>:size = comm.Get_size()
[1,1]<stdout>:
[1,1]<stdout>:nbHexa = 8 ** params["refinements"]
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:def memory_peak(mess=None):
[1,1]<stdout>:    """Return memory peak in MB"""
[1,1]<stdout>:    return int(getrusage(RUSAGE_SELF).ru_maxrss / 1024)
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:class ChronoCtxMgGen:
[1,1]<stdout>:    stats = {}
[1,1]<stdout>:
[1,1]<stdout>:    def __init__(self, what):
[1,1]<stdout>:        self._what = what
[1,1]<stdout>:
[1,1]<stdout>:    def __enter__(self):
[1,1]<stdout>:        self.start = datetime.now()
[1,1]<stdout>:
[1,1]<stdout>:    def __exit__(self, exctype, exc, tb):
[1,1]<stdout>:        self.stop = datetime.now()
[1,1]<stdout>:        delta = self.stop - self.start
[1,1]<stdout>:        mem = memory_peak(self._what)
[1,1]<stdout>:        self.stats[self._what] = [delta.total_seconds(), mem]
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:class ChronoCtxMg(ChronoCtxMgGen):
[1,1]<stdout>:    pass
[1,1]<stdout>:    # def __init__(self, what):
[1,1]<stdout>:    #     ChronoCtxMgGen.__init__(self, what)
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:def write_stats(nume_ddl):
[1,1]<stdout>:    if rank == 0:
[1,1]<stdout>:        print("TITLE: TEST PERF CUBE")
[1,1]<stdout>:        print()
[1,1]<stdout>:        print("NB PROC")
[1,1]<stdout>:        print(size)
[1,1]<stdout>:        print()
[1,1]<stdout>:        print(
[1,1]<stdout>:            "COMMAND, TIME MIN (s), TIME MAX (s), TIME MEAN (s), MEM MIN (Mo), MEM MAX (Mo), MEM MEAN (Mo)"
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    for key, values in stats.items():
[1,1]<stdout>:        time = comm.gather(values[0], root=0)
[1,1]<stdout>:        mem = comm.gather(values[1], root=0)
[1,1]<stdout>:        if rank == 0:
[1,1]<stdout>:            print(
[1,1]<stdout>:                key
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(min(time))
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(max(time))
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(mean(time))
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(min(mem))
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(max(mem))
[1,1]<stdout>:                + ", "
[1,1]<stdout>:                + str(m[1,1]<stdout>:ean(mem))
[1,1]<stdout>:            )
[1,1]<stdout>:
[1,1]<stdout>:    mesh = nume_ddl.getMesh()
[1,1]<stdout>:    nodes = len(mesh.getInnerNodes())
[1,1]<stdout>:    nodes = comm.allreduce(nodes, CA.MPI.SUM)
[1,1]<stdout>:
[1,1]<stdout>:    if rank == 0:
[1,1]<stdout>:        print()
[1,1]<stdout>:        print("NB CELLS, NB NODES, NB DOFS")
[1,1]<stdout>:        print(str(nbHexa) + ", " + str(nodes) + ", " + str(nume_ddl.getNumberOfDofs()))
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:def print_markdown_table(data, refine, nbcells, nbnodes, nbdofs):
[1,1]<stdout>:    """Print a table of the mean time as a Markdown table."""
[1,1]<stdout>:
[1,1]<stdout>:    def show(*args, **kwargs):
[1,1]<stdout>:        if rank == 0:
[1,1]<stdout>:            print(*args, **kwargs)
[1,1]<stdout>:
[1,1]<stdout>:    fmti = "| {0:<16s} | {1:11,d} |"
[1,1]<stdout>:    fmtt = "| {0:<16s} | {1:11.2f} |"
[1,1]<stdout>:    separ = "| :--------------- | ----------: |"
[1,1]<stdout>:    show(fmti.format("Refinement", refine))
[1,1]<stdout>:    show(separ)
[1,1]<stdout>:    show(fmti.format("Number of cells", nbcells).replace(",", " "))
[1,1]<stdout>:    show(fmti.format("Number of nodes", nbnodes).replace(",", " "))
[1,1]<stdout>:    show(fmti.format("Number of DOFs", nbdofs).replace(",", " "))
[1,1]<stdout>:    show(fmti.format("Number of procs", size).replace(",", " "))
[1,1]<stdout>:    show(fmti.format("Nb of DOFs/proc", nbdofs // size).replace(",", " "))
[1,1]<stdout>:    for key, values in data.items():
[1,1]<stdout>:        times = comm.gather(values[0], root=0)
[1,1]<stdout>:        # mem = comm.gather(values[1], root=0)
[1,1]<stdout>:        if rank == 0:
[1,1]<stdout>:            show(fmtt.format(key, mean(times)))
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:# petscInitialize('-ksp_monitor_true_residual -stats' )
[1,1]<stdout>:petscInitialize("-ksp_monitor_true_residual -log_view")
[1,1]<stdout>:
[1,1]<stdout>:with ChronoCtxMg("Total"):
[1,1]<stdout>:    with ChronoCtxMg("Build mesh"):
[1,1]<stdout>:        if params["parallel"] == "HPC":
[1,1]<stdout>:            mesh = CA.ParallelMesh.buildCube(refine=params["refinements"])
[1,1]<stdout>:        else:
[1,1]<stdout>:            mesh = CA.Mesh.buildCube(refine=params["refinements"])
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Model"):
[1,1]<stdout>:        model = AFFE_MODELE(
[1,1]<stdout>:            MAILLAGE=mesh,
[1,1]<stdout>:            AFFE=_F(
[1,1]<stdout>:                TOUT="OUI",
[1,1]<stdout>:                PHENOMENE="MECANIQUE",
[1,1]<stdout>:                MODELISATION="3D",
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Material"):
[1,1]<stdout>:        steel = DEFI_MATERIAU(
[1,1]<stdout>:            ELAS=_F(
[1,1]<stdout>:                E=200000.0,
[1,1]<stdout>:                NU=0.3,
[1,1]<stdout>:            ),
[1,1]<stdout>:            ECRO_LINE=_F(
[1,1]<stdout>:    [1,1]<stdout>:            D_SIGM_EPSI=2000.0,
[1,1]<stdout>:                SY=200.0,
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:        mater = AFFE_MATERIAU(
[1,1]<stdout>:            MAILLAGE=mesh,
[1,1]<stdout>:            AFFE=_F(
[1,1]<stdout>:                TOUT="OUI",
[1,1]<stdout>:                MATER=steel,
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Boundary conditions"):
[1,1]<stdout>:        block = AFFE_CHAR_CINE(
[1,1]<stdout>:            MODELE=model,
[1,1]<stdout>:            MECA_IMPO=(
[1,1]<stdout>:                _F(
[1,1]<stdout>:                    GROUP_MA="LEFT",
[1,1]<stdout>:                    DX=0,
[1,1]<stdout>:                    DY=0.0,
[1,1]<stdout>:                    DZ=0.0,
[1,1]<stdout>:                ),
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:        imposed_displ = AFFE_CHAR_CINE(
[1,1]<stdout>:            MODELE=model,
[1,1]<stdout>:            MECA_IMPO=(
[1,1]<stdout>:                _F(
[1,1]<stdout>:                    GROUP_MA="RIGHT",
[1,1]<stdout>:                    DY=0.001,
[1,1]<stdout>:                    DZ=0.001,
[1,1]<stdout>:                ),
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Create matrix"):
[1,1]<stdout>:        stiff_elem = CALC_MATR_ELEM(
[1,1]<stdout>:            MODELE=model,
[1,1]<stdout>:            OPTION="RIGI_MECA",
[1,1]<stdout>:            CHAM_MATER=mater,
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Numbering"):
[1,1]<stdout>:        dofNum = NUME_DDL(
[1,1]<stdout>:            MATR_RIGI=stiff_elem,
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Assembly"):
[1,1]<stdout>:        stiffness = ASSE_MATRICE(
[1,1]<stdout>:            MATR_ELEM=stiff_elem,
[1,1]<stdout>:            NUME_DDL=dofNum,
[1,1]<stdout>:            CHAR_CINE=(block, imposed_displ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Build RHS"):
[1,1]<stdout>:        rhs = CREA_CHAMP(
[1,1]<stdout>:            TYPE_CHAM="NOEU_DEPL_R",
[1,1]<stdout>:            OPERATION="AFFE",
[1,1]<stdout>:            MAILLAGE=mesh,
[1,1]<stdout>:            AFFE=_F(
[1,1]<stdout>:                TOUT="OUI",
[1,1]<stdout>:                NOM_CMP=(
[1,1]<stdout>:                    "DX",
[1,1]<stdout>:                    "DY",
[1,1]<stdout>:                    "DZ",
[1,1]<stdout>:                ),
[1,1]<stdout>:                VALE=(
[1,1]<stdout>:                    0.0,
[1,1]<stdout>:                    0.0,
[1,1]<stdout>:                    0.0,
[1,1]<stdout>:                ),
[1,1]<stdout>:            ),
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:        load_vector = CALC_CHAR_CINE(NUME_DDL=dofNum, CHAR_CINE=(block, imposed_displ))
[1,1]<stdout>:
[1,1]<stdout>:    if params["solver"] == "PETSC":
[1,1]<stdout>:        solver = CA.PetscSolver(RENUM="SANS", PRE_COND="GAMG")
[1,1]<stdout>:    elif params["solver"] == "MUMPS":
[1,1]<stdout>:        solver = CA.MumpsSolver(
[1,1]<stdout>:            MATR_DISTRIBUEE="OUI",
[1,1]<stdout>:            RENUM="PARMETIS",
[1,1]<stdout>:            ACCELERATION="FR+",
[1,1]<stdout>:            POSTTRAITEMENTS="MINI",
[1,1]<stdout>:        )
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Factorize"):
[1,1]<stdout>:        solver.factorize(stiffness)
[1,1]<stdout>:
[1,1]<stdout>:    with ChronoCtxMg("Solve"):
[1,1]<stdout>:        resu = solver.solve(rhs, load_vector)
[1,1]<stdout>:
[1,1]<stdout>:# write_stats(dofNum)
[1,1]<stdout>:nbNodes = len(mesh.getInnerNodes())
[1,1]<stdout>:if params["parallel"] == "HPC":
[1,1]<stdout>:    nbNodes = comm.allreduce(nbNodes, CA.MPI.SUM)
[1,1]<stdout>:nbDOFs = dofNum.getNumberOfDOFs()
[1,1]<stdout>:print_markdown_table(ChronoCtxMg.stats, params["refinements"], nbHexa, nbNodes, nbDOFs)
[1,1]<stdout>:
[1,1]<stdout>:CA.close()
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:# ------------------------------------------------------------------------------
[1,1]<stdout>:Command line #1:
[1,1]<stdout>:    ulimit -c unlimited ; ulimit -t 108000 ; ( /opt/venv/bin/python3 -m mpi4py /home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/Cube_perf.py --last --tpmax 86400 ; echo $? > _exit_code_ ) 2>&1 | tee -a fort.6
[1,0]<stdout>:setting '--memory' value to 3686.40 MB (keyword RESERVE_MEMOIRE)
[1,1]<stdout>:setting '--memory' value to 3686.40 MB (keyword RESERVE_MEMOIRE)
[1,0]<stdout>:checking MPI initialization...
[1,0]<stdout>:using COMM_WORLD.
[1,0]<stdout>:MPI is initialized.
[1,0]<stdout>:Ouverture en écriture du fichier ./vola.1
[1,0]<stdout>:
[1,1]<stdout>:checking MPI initialization...
[1,1]<stdout>:using COMM_WORLD.
[1,1]<stdout>:MPI is initialized.
[1,1]<stdout>:Ouverture en écriture du fichier ./vola.1
[1,1]<stdout>:
[1,0]<stdout>:<INFO> Démarrage de l'exécution.
[1,0]<stdout>:
[1,0]<stdout>:                       -- CODE_ASTER -- VERSION : DÉVELOPPEMENT (unstable) --                       
[1,1]<stdout>:<INFO> Démarrage de l'exécution.
[1,1]<stdout>:
[1,0]<stdout>:                               Version 17.2.4 modifiée le 20/01/2025                                
[1,0]<stdout>:                               révision f855b56619c7 - branche 'main'                               
[1,1]<stdout>:                       -- CODE_ASTER -- VERSION : DÉVELOPPEMENT (unstable) --                       
[1,0]<stdout>:                                   Copyright EDF R&D 1991 - 2025                                    
[1,0]<stdout>:                                                                                                    
[1,0]<stdout>:                              Exécution du : Thu Jan 23 16:26:00 2025                               
[1,0]<stdout>:                                  Nom de la machine : 8b87b9d0b29a                                  
[1,0]<stdout>:                                        Architecture : 64bit                                        
[1,0]<stdout>:                                    Type de processeur : aarch64                                    
[1,0]<stdout>:        Système d'exploitation : Linux-5.10.226-214.880.amzn2.aarch64-aarch64-with-glibc2.40        
[1,0]<stdout>:                                  Langue des messages : en (UTF-8)                                  
[1,1]<stdout>:                               Version 17.2.4 modifiée le 20/01/2025                                
[1,1]<stdout>:                               révision f855b56619c7 - branche 'main'                               
[1,0]<stdout>:                                     Version de Python : 3.11.2                                     
[1,0]<stdout>:                                     Version de NumPy : 1.24.2                                      
[1,1]<stdout>:                                   Copyright EDF R&D 1991 - 2025                                    
[1,1]<stdout>:                                                                                                    
[1,1]<stdout>:                              Exécution du : Thu Jan 23 16:26:00 2025                               
[1,1]<stdout>:                                  Nom de la machine : 8b87b9d0b29a                                  
[1,1]<stdout>:                                        Architecture : 64bit                                        
[1,1]<stdout>:                                    Type de processeur : aarch64                                    
[1,1]<stdout>:        Système d'exploitation : Linux-5.10.226-214.880.amzn2.aarch64-aarch64-with-glibc2.40        
[1,1]<stdout>:                                  Langue des messages : en (UTF-8)                                  
[1,0]<stdout>:                                      Parallélisme MPI : actif                                      
[1,0]<stdout>:                                   Rang du processeur courant : 0                                   
[1,0]<stdout>:                               Nombre de processeurs MPI utilisés : 2                               
[1,1]<stdout>:                                     Version de Python : 3.11.2                                     
[1,1]<stdout>:                                     Version de NumPy : 1.24.2                                      
[1,0]<stdout>:                                    Parallélisme OpenMP : actif                                     
[1,0]<stdout>:                              Nombre de processus OpenMP utilisés : 1                               
[1,1]<stdout>:                                      Parallélisme MPI : actif                                      
[1,1]<stdout>:                                   Rang du processeur courant : 1                                   
[1,1]<stdout>:                               Nombre de processeurs MPI utilisés : 2                               
[1,1]<stdout>:                                    Parallélisme OpenMP : actif                                     
[1,1]<stdout>:                              Nombre de processus OpenMP utilisés : 1                               
[1,0]<stdout>:                               Version de la librairie HDF5 : 1.10.9                                
[1,0]<stdout>:                                Version de la librairie MED : 4.1.1                                 
[1,1]<stdout>:                               Version de la librairie HDF5 : 1.10.9                                
[1,0]<stdout>:                               Version de la librairie MFront : 4.2.0                               
[1,1]<stdout>:                                Version de la librairie MED : 4.1.1                                 
[1,0]<stdout>:                               Version de la librairie MUMPS : 5.6.2                                
[1,1]<stdout>:                               Version de la librairie MFront : 4.2.0                               
[1,0]<stdout>:                              Version de la librairie PETSc : 3.20.5p0                              
[1,1]<stdout>:                               Version de la librairie MUMPS : 5.6.2                                
[1,0]<stdout>:                               Version de la librairie SCOTCH : 7.0.4                               
[1,1]<stdout>:                              Version de la librairie PETSc : 3.20.5p0                              
[1,1]<stdout>:                               Version de la librairie SCOTCH : 7.0.4                               
[1,0]<stdout>:
[1,0]<stdout>:starting the execution...
[1,1]<stdout>:
[1,1]<stdout>:starting the execution...
[1,0]<stdout>:Valeur initiale du temps CPU maximum =   86400 secondes
[1,0]<stdout>:  Valeur du temps CPU maximum passé aux commandes =   77760 secondes
[1,0]<stdout>:  Réserve CPU prévue = 8640 secondes
[1,0]<stdout>:
[1,1]<stdout>:Valeur initiale du temps CPU maximum =   86400 secondes
[1,1]<stdout>:  Valeur du temps CPU maximum passé aux commandes =   77760 secondes
[1,1]<stdout>:  Réserve CPU prévue = 8640 secondes
[1,1]<stdout>:
[1,0]<stdout>:Ouverture en écriture du fichier ./glob.1
[1,0]<stdout>:
[1,1]<stdout>:Ouverture en écriture du fichier ./glob.1
[1,1]<stdout>:
[1,0]<stdout>:Ouverture en écriture du fichier ./vola.1
[1,0]<stdout>:
[1,1]<stdout>:Ouverture en écriture du fichier ./vola.1
[1,1]<stdout>:
[1,1]<stdout>:Ouverture en lecture du fichier /opt/aster/install/mpi/lib/aster/elem.1
[1,1]<stdout>:
[1,0]<stdout>:Ouverture en lecture du fichier /opt/aster/install/mpi/lib/aster/elem.1
[1,0]<stdout>:
[1,0]<stdout>:Nom de la base                          :  ELEMBASE
[1,0]<stdout>:     Créée avec la version                   :  17.02.04
[1,0]<stdout>:     Nombre d'enregistrements utilisés       :  45
[1,0]<stdout>:     Nombre d'enregistrements maximum        :  512
[1,0]<stdout>:     Nombre d'enregistrements par fichier    :  512
[1,0]<stdout>:     Longueur d'enregistrement (octets)      :  819200
[1,0]<stdout>:     Nombre d'identificateurs utilisés       :  123
[1,0]<stdout>:     Taille maximum du répertoire            :  300
[1,0]<stdout>:     Pourcentage d'utilisation du répertoire :  41 %
[1,0]<stdout>:
[1,1]<stdout>:Nom de la base                          :  ELEMBASE
[1,1]<stdout>:     Créée avec la version                   :  17.02.04
[1,1]<stdout>:     Nombre d'enregistrements utilisés       :  45
[1,1]<stdout>:     Nombre d'enregistrements maximum        :  512
[1,1]<stdout>:     Nombre d'enregistrements par fichier    :  512
[1,1]<stdout>:     Longueur d'enregistrement (octets)      :  819200
[1,1]<stdout>:     Nombre d'identificateurs utilisés       :  123
[1,1]<stdout>:     Taille maximum du répertoire            :  300
[1,1]<stdout>:     Pourcentage d'utilisation du répertoire :  41 %
[1,1]<stdout>:
[1,0]<stdout>:Ouverture en lecture du fichier /opt/aster/install/mpi/lib/aster/elem.1
[1,0]<stdout>:
[1,1]<stdout>:Ouverture en lecture du fichier /opt/aster/install/mpi/lib/aster/elem.1
[1,1]<stdout>:
[1,1]<stdout>:Nom de la base                          :  ELEMBASE
[1,1]<stdout>:     Nombre d'enregistrements utilisés       :  45
[1,1]<stdout>:     Nombre d'enregistrements maximum        :  512
[1,1]<stdout>:     Nombre d'enregistrements par fichier    :  512
[1,1]<stdout>:     Longueur d'enregistrement (octets)      :  819200
[1,1]<stdout>:     Nombre total d'accès en lecture         :  63
[1,1]<stdout>:     Volume des accès en lecture             :         49.22 Mo.
[1,1]<stdout>:     Nombre total d'accès en écriture        :  0
[1,1]<stdout>:     Volume des accès en écriture            :          0.00 Mo.
[1,1]<stdout>:     Nombre d'identificateurs utilisés       :  123
[1,1]<stdout>:     Taille maximum du répertoire            :  300
[1,1]<stdout>:     Pourcentage d'utilisation du répertoire :  41 %
[1,1]<stdout>:
[1,1]<stdout>:Relecture des catalogues des éléments faite.
[1,1]<stdout>:
[1,0]<stdout>:Nom de la base                          :  ELEMBASE
[1,0]<stdout>:     Nombre d'enregistrements utilisés       :  45
[1,0]<stdout>:     Nombre d'enregistrements maximum        :  512
[1,0]<stdout>:     Nombre d'enregistrements par fichier    :  512
[1,0]<stdout>:     Longueur d'enregistrement (octets)      :  819200
[1,0]<stdout>:     Nombre total d'accès en lecture         :  63
[1,0]<stdout>:     Volume des accès en lecture             :         49.22 Mo.
[1,0]<stdout>:     Nombre total d'accès en écriture        :  0
[1,0]<stdout>:     Volume des accès en écriture            :          0.00 Mo.
[1,0]<stdout>:     Nombre d'identificateurs utilisés       :  123
[1,0]<stdout>:     Taille maximum du répertoire            :  300
[1,0]<stdout>:     Pourcentage d'utilisation du répertoire :  41 %
[1,0]<stdout>:
[1,1]<stdout>:Fin de lecture (durée  0.015074  s.) 
[1,1]<stdout>:
[1,0]<stdout>:Relecture des catalogues des éléments faite.
[1,0]<stdout>:
[1,0]<stdout>:Fin de lecture (durée  0.015168  s.) 
[1,0]<stdout>:
[1,1]<stdout>:                      Mémoire limite pour l'allocation dynamique : 4215.81 Mo                       
[1,1]<stdout>:                         ajouté à l'initialisation du processus : 589.54 Mo                         
[1,1]<stdout>:                               Limite cible du processus : 4805.34 Mo                               
[1,0]<stdout>:                      Mémoire limite pour l'allocation dynamique : 4215.86 Mo                       
[1,0]<stdout>:                         ajouté à l'initialisation du processus : 589.54 Mo                         
[1,0]<stdout>:                               Limite cible du processus : 4805.41 Mo                               
[1,1]<stdout>:                         Taille limite des fichiers d'échange : 2048.00 Go                          
[1,0]<stdout>:                         Taille limite des fichiers d'échange : 2048.00 Go                          
[1,1]<stdout>:# Mémoire (Mo) :   589.54 /   580.63 /   209.22 /   185.03 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Mémoire (Mo) :   589.54 /   580.64 /   209.22 /   185.03 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0001   user+syst:        0.02s (syst:        0.10s, elaps:        0.11s)
[1,0]<stdout>:# Fin commande #0001   user+syst:        0.02s (syst:        0.09s, elaps:        0.11s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:PETSc initialized...
[1,0]<stdout>:PETSc initialized...
[1,0]<stdout>:Nom MED du maillage : PARALLEPIPED
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:------------ MAILLAGE 00000001 - IMPRESSIONS NIVEAU  1 ------------
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:NOMBRE DE NOEUDS                      274625
[1,0]<stdout>:
[1,0]<stdout>:NOMBRE DE MAILLES                     287488
[1,0]<stdout>:                              SEG2                  768
[1,0]<stdout>:                              QUAD4               24576
[1,0]<stdout>:                              HEXA8              262144
[1,0]<stdout>:
[1,0]<stdout>:NOMBRE DE GROUPES DE NOEUDS                8
[1,0]<stdout>:
[1,0]<stdout>:NOMBRE DE GROUPES DE MAILLES              19
[1,0]<stdout>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt190
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0002 de /opt/aster/install/mpi/lib/aster/code_aster/Helpers/LogicalUnit.py, ligne 190
[1,0]<stdout>:DEFI_FICHIER(ACCES='NEW',
[1,0]<stdout>:             ACTION='ASSOCIER',
[1,0]<stdout>:             FICHIER='/tmp/buildCuberczd9aun/buildCube.med',
[1,0]<stdout>:             TYPE='BINARY',
[1,0]<stdout>:             UNITE=99)
[1,0]<stdout>:
[1,0]<stdout>:Deleting '/tmp/buildCuberczd9aun/buildCube.med': [1,0]<stdout>:No such file or directory
[1,0]<stdout>:# Mémoire (Mo) :  1111.07 /   779.59 /   249.04 /   213.86 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0002   user+syst:        0.00s (syst:        0.00s, elaps:        0.00s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:Création du fichier au format MED 3.3.1.
[1,0]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt190
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0003 de /opt/aster/install/mpi/lib/aster/code_aster/Helpers/LogicalUnit.py, ligne 190
[1,0]<stdout>:DEFI_FICHIER(ACTION='LIBERER',
[1,0]<stdout>:             UNITE=99)
[1,0]<stdout>:
[1,0]<stdout>:# Mémoire (Mo) :  1111.07 /   779.71 /   282.08 /   250.98 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0003   user+syst:        0.00s (syst:        0.00s, elaps:        0.00s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:<INFO> Activation du mode parallélisme distribué.
[1,1]<stdout>:<INFO> Activation du mode parallélisme distribué.
[1,0]<stdout>:
[1,0]<stdout>:Nom MED du maillage : 00000001
[1,0]<stdout>:
[1,1]<stdout>:Nom MED du maillage : 00000001
[1,1]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,0]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt282
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt282
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0004 de /opt/aster/install/mpi/lib/aster/code_aster/ObjectsExt/parallelmesh_ext.py,
[1,0]<stdout>:ligne 282
[1,1]<stdout>:# Commande #0002 de /opt/aster/install/mpi/lib/aster/code_aster/ObjectsExt/parallelmesh_ext.py,
[1,1]<stdout>:ligne 282
[1,0]<stdout>:CREA_MAILLAGE(INFO=1,
[1,0]<stdout>:              MAILLAGE='<00000002>',
[1,0]<stdout>:              RAFFINEMENT=_F(NIVEAU=1,
[1,0]<stdout>:                             TOUT='OUI'))
[1,0]<stdout>:
[1,1]<stdout>:CREA_MAILLAGE(INFO=1,
[1,1]<stdout>:              MAILLAGE='<00000002>',
[1,1]<stdout>:              RAFFINEMENT=_F(NIVEAU=1,
[1,1]<stdout>:                             TOUT='OUI'))
[1,1]<stdout>:
[1,0]<stdout>:
[1,1]<stdout>:
[1,0]<stdout>:------------ MAILLAGE 00000004 - IMPRESSIONS NIVEAU  1 ------------
[1,0]<stdout>:
[1,1]<stdout>:------------ MAILLAGE 00000004 - IMPRESSIONS NIVEAU  1 ------------
[1,1]<stdout>:
[1,1]<stdout>:ASTER 17.02.04 CONCEPT 00000004 CALCULE LE 23/01/2025 A 16:26:24 DE TYPE        
[1,0]<stdout>:ASTER 17.02.04 CONCEPT 00000004 CALCULE LE 23/01/2025 A 16:26:24 DE TYPE        
[1,1]<stdout>:MAILLAGE_P                                                                      
[1,1]<stdout>:
[1,0]<stdout>:MAILLAGE_P                                                                      
[1,0]<stdout>:
[1,0]<stdout>:NOMBRE DE NOEUDS                     1102115
[1,0]<stdout>:
[1,1]<stdout>:NOMBRE DE NOEUDS                     1079048
[1,0]<stdout>:NOMBRE DE MAILLES                    1118882
[1,1]<stdout>:
[1,0]<stdout>:                              SEG2                  770
[1,0]<stdout>:                              QUAD4               49608
[1,0]<stdout>:                              HEXA8             1068504
[1,0]<stdout>:
[1,1]<stdout>:NOMBRE DE MAILLES                    1095612
[1,1]<stdout>:                              SEG2                  770
[1,1]<stdout>:                              QUAD4               49220
[1,0]<stdout>:NOMBRE DE GROUPES DE NOEUDS                4
[1,1]<stdout>:                              HEXA8             1045622
[1,0]<stdout>:
[1,1]<stdout>:
[1,0]<stdout>:NOMBRE DE GROUPES DE MAILLES              14
[1,0]<stdout>:
[1,1]<stdout>:NOMBRE DE GROUPES DE NOEUDS                4
[1,1]<stdout>:
[1,1]<stdout>:NOMBRE DE GROUPES DE MAILLES              14
[1,0]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:
[1,0]<stdout>:
[1,1]<stdout>:--------------------------------------------------------------------------------
[1,1]<stdout>:
[1,0]<stdout>:#4      Communications MPI                                CPU (USER+SYST/SYST/ELAPS):      0.01      0.00      0.00
[1,1]<stdout>:#4      Communications MPI                                CPU (USER+SYST/SYST/ELAPS):      0.12      0.00      0.12
[1,1]<stdout>:# Résultat commande #0002 (CREA_MAILLAGE): '<00000004>' de type <ParallelMesh>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1296.25 /   526.86 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0002   user+syst:       13.50s (syst:        3.53s, elaps:       17.03s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Résultat commande #0004 (CREA_MAILLAGE): '<00000004>' de type <ParallelMesh>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1417.45 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0004   user+syst:       13.52s (syst:        3.57s, elaps:       17.08s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt131
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0003 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 131
[1,1]<stdout>:model = AFFE_MODELE(AFFE=_F(MODELISATION='3D',
[1,1]<stdout>:                            PHENOMENE='MECANIQUE',
[1,1]<stdout>:                            TOUT='OUI'),
[1,1]<stdout>:                    DISTRIBUTION=_F(METHODE='CENTRALISE'),
[1,1]<stdout>:                    INFO=1,
[1,1]<stdout>:                    MAILLAGE='<00000004>',
[1,1]<stdout>:                    VERI_JACOBIEN='OUI',
[1,1]<stdout>:                    VERI_NORM_IFS='OUI',
[1,1]<stdout>:                    VERI_PLAN='OUI')
[1,1]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt131
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0005 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 131
[1,0]<stdout>:model = AFFE_MODELE(AFFE=_F(MODELISATION='3D',
[1,0]<stdout>:                            PHENOMENE='MECANIQUE',
[1,0]<stdout>:                            TOUT='OUI'),
[1,0]<stdout>:                    DISTRIBUTION=_F(METHODE='CENTRALISE'),
[1,0]<stdout>:                    INFO=1,
[1,0]<stdout>:                    MAILLAGE='<00000004>',
[1,0]<stdout>:                    VERI_JACOBIEN='OUI',
[1,0]<stdout>:                    VERI_NORM_IFS='OUI',
[1,0]<stdout>:                    VERI_PLAN='OUI')
[1,0]<stdout>:
[1,1]<stdout>:Sur les 1095612 mailles du maillage 00000004, on a demandé l'affectation de 1095612, on a pu en
[1,1]<stdout>:affecter 1095612.
[1,0]<stdout>:Sur les 1118882 mailles du maillage 00000004, on a demandé l'affectation de 1118882, on a pu en
[1,0]<stdout>:affecter 1118882.
[1,1]<stdout>:Modélisation     Formulation      Type maille  Élément fini     Nombre
[1,1]<stdout>:_                _                SEG2         MECA_ARETE2      770
[1,1]<stdout>:_                _                QUAD4        MECA_FACE4       49220
[1,1]<stdout>:3D               _                HEXA8        MECA_HEXA8       1045622
[1,0]<stdout>:Modélisation     Formulation      Type maille  Élément fini     Nombre
[1,0]<stdout>:_                _                SEG2         MECA_ARETE2      770
[1,0]<stdout>:_                _                QUAD4        MECA_FACE4       49608
[1,0]<stdout>:3D               _                HEXA8        MECA_HEXA8       1068504
[1,1]<stdout>:#2      Calculs elementaires et assemblages               CPU (USER+SYST/SYST/ELAPS):      0.58      0.00      0.57
[1,1]<stdout>:#4      Communications MPI                                CPU (USER+SYST/SYST/ELAPS):      0.03      0.00      0.03
[1,0]<stdout>:#2      Calculs elementaires et assemblages               CPU (USER+SYST/SYST/ELAPS):      0.60      0.00      0.60
[1,0]<stdout>:#4      Communications MPI                                CPU (USER+SYST/SYST/ELAPS):      0.00      0.00      0.00
[1,0]<stdout>:# Résultat commande #0005 (AFFE_MODELE): model ('<00000005>') de type <Model>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1407.64 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0005   user+syst:        3.71s (syst:        0.01s, elaps:        3.72s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Résultat commande #0003 (AFFE_MODELE): model ('<00000005>') de type <Model>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1345.70 /   561.10 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0003   user+syst:        3.74s (syst:        0.00s, elaps:        3.74s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt141
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0006 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 141
[1,0]<stdout>:steel = DEFI_MATERIAU(ECRO_LINE=_F(D_SIGM_EPSI=2000.0,
[1,0]<stdout>:                                   SY=200.0),
[1,0]<stdout>:                      ELAS=_F(B_ENDOGE=0.0,
[1,0]<stdout>:                              COEF_AMOR=1.0,
[1,0]<stdout>:                              E=200000.0,
[1,0]<stdout>:                              K_DESSIC=0.0,
[1,0]<stdout>:                              NU=0.3),
[1,0]<stdout>:                      INFO=1)
[1,0]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt141
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0004 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 141
[1,1]<stdout>:steel = DEFI_MATERIAU(ECRO_LINE=_F(D_SIGM_EPSI=2000.0,
[1,1]<stdout>:                                   SY=200.0),
[1,1]<stdout>:                      ELAS=_F(B_ENDOGE=0.0,
[1,1]<stdout>:                              COEF_AMOR=1.0,
[1,1]<stdout>:                              E=200000.0,
[1,1]<stdout>:                              K_DESSIC=0.0,
[1,1]<stdout>:                              NU=0.3),
[1,1]<stdout>:                      INFO=1)
[1,1]<stdout>:
[1,0]<stdout>:# Résultat commande #0006 (DEFI_MATERIAU): steel ('<00000006>') de type <Material>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1407.64 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0006   user+syst:        0.02s (syst:        0.00s, elaps:        0.02s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Résultat commande #0004 (DEFI_MATERIAU): steel ('<00000006>') de type <Material>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1345.70 /   561.10 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0004   user+syst:        0.02s (syst:        0.00s, elaps:        0.02s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt152
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0007 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 152
[1,0]<stdout>:mater = AFFE_MATERIAU(AFFE=_F(MATER=steel,
[1,0]<stdout>:                              TOUT='OUI'),
[1,0]<stdout>:                      INFO=1,
[1,0]<stdout>:                      MAILLAGE='<00000004>')
[1,0]<stdout>:
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt152
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0005 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 152
[1,1]<stdout>:mater = AFFE_MATERIAU(AFFE=_F(MATER=steel,
[1,1]<stdout>:                              TOUT='OUI'),
[1,1]<stdout>:                      INFO=1,
[1,1]<stdout>:                      MAILLAGE='<00000004>')
[1,1]<stdout>:
[1,1]<stdout>:# Résultat commande #0005 (AFFE_MATERIAU): mater ('<00000007>') de type <MaterialField>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1345.70 /   561.10 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0005   user+syst:        0.01s (syst:        0.00s, elaps:        0.01s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Résultat commande #0007 (AFFE_MATERIAU): mater ('<00000007>') de type <MaterialField>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1407.64 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0007   user+syst:        0.01s (syst:        0.00s, elaps:        0.01s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt161
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0006 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 161
[1,1]<stdout>:block = AFFE_CHAR_CINE(INFO=1,
[1,1]<stdout>:                       MECA_IMPO=_F(DX=0,
[1,1]<stdout>:                                    DY=0.0,
[1,1]<stdout>:                                    DZ=0.0,
[1,1]<stdout>:                                    GROUP_MA='LEFT'),
[1,1]<stdout>:                       MODELE=model,
[1,1]<stdout>:                       SYNTAXE='NON')
[1,1]<stdout>:
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt161
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0008 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 161
[1,0]<stdout>:block = AFFE_CHAR_CINE(INFO=1,
[1,0]<stdout>:                       MECA_IMPO=_F(DX=0,
[1,0]<stdout>:                                    DY=0.0,
[1,0]<stdout>:                                    DZ=0.0,
[1,0]<stdout>:                                    GROUP_MA='LEFT'),
[1,0]<stdout>:                       MODELE=model,
[1,0]<stdout>:                       SYNTAXE='NON')
[1,0]<stdout>:
[1,1]<stdout>:# Résultat commande #0006 (AFFE_CHAR_CINE): block ('<00000008>') de type <MechanicalDirichletBC>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1345.70 /   561.10 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0006   user+syst:        0.55s (syst:        0.00s, elaps:        0.55s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt173
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0007 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 173
[1,1]<stdout>:imposed_displ = AFFE_CHAR_CINE(INFO=1,
[1,1]<stdout>:                               MECA_IMPO=_F(DY=0.001,
[1,1]<stdout>:                                            DZ=0.001,
[1,1]<stdout>:                                            GROUP_MA='RIGHT'),
[1,1]<stdout>:                               MODELE=model,
[1,1]<stdout>:                               SYNTAXE='NON')
[1,1]<stdout>:
[1,0]<stdout>:# Résultat commande #0008 (AFFE_CHAR_CINE): block ('<00000008>') de type <MechanicalDirichletBC>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1407.64 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0008   user+syst:        0.55s (syst:        0.00s, elaps:        0.56s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt173
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0009 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 173
[1,0]<stdout>:imposed_displ = AFFE_CHAR_CINE(INFO=1,
[1,0]<stdout>:                               MECA_IMPO=_F(DY=0.001,
[1,0]<stdout>:                                            DZ=0.001,
[1,0]<stdout>:                                            GROUP_MA='RIGHT'),
[1,0]<stdout>:                               MODELE=model,
[1,0]<stdout>:                               SYNTAXE='NON')
[1,0]<stdout>:
[1,1]<stdout>:# Résultat commande #0007 (AFFE_CHAR_CINE): imposed_displ ('<00000009>') de type
[1,1]<stdout>:<MechanicalDirichletBC>
[1,1]<stdout>:# Mémoire (Mo) :  6710.00 /  1345.70 /   561.10 /   485.05 (VmPeak / VmSize / Optimum / Minimum)
[1,1]<stdout>:# Fin commande #0007   user+syst:        0.55s (syst:        0.00s, elaps:        0.55s)
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:
[1,1]<stdout>:.. _stg1_txt185
[1,1]<stdout>:# ----------------------------------------------------------------------------------------------
[1,1]<stdout>:# Commande #0008 de
[1,1]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,1]<stdout>:Cube_perf.py, ligne 185
[1,1]<stdout>:stiff_elem = CALC_MATR_ELEM(CALC_ELEM_MODELE='OUI',
[1,1]<stdout>:                            CHAM_MATER=mater,
[1,1]<stdout>:                            INST=0.0,
[1,1]<stdout>:                            MODELE=model,
[1,1]<stdout>:                            MODE_FOURIER=0,
[1,1]<stdout>:                            OPTION='RIGI_MECA')
[1,1]<stdout>:
[1,0]<stdout>:# Résultat commande #0009 (AFFE_CHAR_CINE): imposed_displ ('<00000009>') de type
[1,0]<stdout>:<MechanicalDirichletBC>
[1,0]<stdout>:# Mémoire (Mo) :  6853.18 /  1407.64 /   576.00 /   525.52 (VmPeak / VmSize / Optimum / Minimum)
[1,0]<stdout>:# Fin commande #0009   user+syst:        0.56s (syst:        0.00s, elaps:        0.55s)
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:
[1,0]<stdout>:.. _stg1_txt185
[1,0]<stdout>:# ----------------------------------------------------------------------------------------------
[1,0]<stdout>:# Commande #0010 de
[1,0]<stdout>:/home/aster/work/Benchmark-CodeAster/opensource-installation-development-main/benchmarks/Cube_files/
[1,0]<stdout>:Cube_perf.py, ligne 185
[1,0]<stdout>:stiff_elem = CALC_MATR_ELEM(CALC_ELEM_MODELE='OUI',
[1,0]<stdout>:                            CHAM_MATER=mater,
[1,0]<stdout>:                            INST=0.0,
[1,0]<stdout>:                            MODELE=model,
[1,0]<stdout>:                            MODE_FOURIER=0,
[1,0]<stdout>:                            OPTION='RIGI_MECA')
[1,0]<stdout>:
